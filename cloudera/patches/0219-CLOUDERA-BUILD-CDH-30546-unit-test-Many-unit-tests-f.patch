From c0475af2e69b7bfe6b741b21aac5ceb9b7b9c90e Mon Sep 17 00:00:00 2001
From: Jimmy Xiang <jxiang@cloudera.com>
Date: Wed, 19 Aug 2015 13:25:46 -0700
Subject: [PATCH 219/275] CLOUDERA-BUILD: CDH-30546: [unit test] Many unit
 tests failing due to similar plan diffs on CDH5.5
 and CDH5.4.X

---
 .../test/results/clientpositive/bucket_many.q.out  |   58 ++++++++++----------
 .../clientpositive/lateral_view_explode2.q.out     |   20 +++----
 .../runtime_skewjoin_mapjoin_spark.q.out           |   16 ++----
 ...roupby_complex_types_multi_single_reducer.q.out |   38 ++++++-------
 .../spark/lateral_view_explode2.q.out              |   24 ++++----
 .../spark/runtime_skewjoin_mapjoin_spark.q.out     |   16 ++----
 .../clientpositive/spark/union_remove_25.q.out     |    2 +-
 .../test/results/clientpositive/udf_in_file.q.out  |    2 +-
 .../clientpositive/udf_nondeterministic.q.out      |   12 ++--
 .../clientpositive/unionall_unbalancedppd.q.out    |   34 +++++-------
 .../vector_aggregate_without_gby.q.out             |   16 ++----
 11 files changed, 106 insertions(+), 132 deletions(-)

diff --git a/ql/src/test/results/clientpositive/bucket_many.q.out b/ql/src/test/results/clientpositive/bucket_many.q.out
index 9f09163..44a1a97 100644
--- a/ql/src/test/results/clientpositive/bucket_many.q.out
+++ b/ql/src/test/results/clientpositive/bucket_many.q.out
@@ -106,37 +106,39 @@ STAGE PLANS:
         /src [src]
       Needs Tagging: false
       Reduce Operator Tree:
-        Select Operator
-          expressions: UDFToInteger(VALUE._col0) (type: int), VALUE._col1 (type: string)
-          outputColumnNames: _col0, _col1
+        Extract
           Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
-          File Output Operator
-            compressed: false
-            GlobalTableId: 1
-#### A masked pattern was here ####
-            NumFilesPerFileSink: 16
+          Select Operator
+            expressions: UDFToInteger(_col0) (type: int), _col1 (type: string)
+            outputColumnNames: _col0, _col1
             Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
+            File Output Operator
+              compressed: false
+              GlobalTableId: 1
+#### A masked pattern was here ####
+              NumFilesPerFileSink: 16
+              Statistics: Num rows: 500 Data size: 5312 Basic stats: COMPLETE Column stats: NONE
 #### A masked pattern was here ####
-            table:
-                input format: org.apache.hadoop.mapred.TextInputFormat
-                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                properties:
-                  bucket_count 256
-                  bucket_field_name key
-                  columns key,value
-                  columns.comments 
-                  columns.types int:string
-#### A masked pattern was here ####
-                  name default.bucket_many
-                  serialization.ddl struct bucket_many { i32 key, string value}
-                  serialization.format 1
-                  serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-#### A masked pattern was here ####
-                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
-                name: default.bucket_many
-            TotalFiles: 256
-            GatherStats: true
-            MultiFileSpray: true
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  properties:
+                    bucket_count 256
+                    bucket_field_name key
+                    columns key,value
+                    columns.comments 
+                    columns.types int:string
+#### A masked pattern was here ####
+                    name default.bucket_many
+                    serialization.ddl struct bucket_many { i32 key, string value}
+                    serialization.format 1
+                    serialization.lib org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+#### A masked pattern was here ####
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  name: default.bucket_many
+              TotalFiles: 256
+              GatherStats: true
+              MultiFileSpray: true
 
   Stage: Stage-0
     Move Operator
diff --git a/ql/src/test/results/clientpositive/lateral_view_explode2.q.out b/ql/src/test/results/clientpositive/lateral_view_explode2.q.out
index e2d24ee..737d562 100644
--- a/ql/src/test/results/clientpositive/lateral_view_explode2.q.out
+++ b/ql/src/test/results/clientpositive/lateral_view_explode2.q.out
@@ -62,20 +62,16 @@ STAGE PLANS:
           mode: mergepartial
           outputColumnNames: _col0, _col1
           Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-          Select Operator
-            expressions: _col0 (type: int), _col1 (type: int)
-            outputColumnNames: _col0, _col1
+          Limit
+            Number of rows: 3
             Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-            Limit
-              Number of rows: 3
+            File Output Operator
+              compressed: false
               Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-              File Output Operator
-                compressed: false
-                Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-                table:
-                    input format: org.apache.hadoop.mapred.TextInputFormat
-                    output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                    serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+              table:
+                  input format: org.apache.hadoop.mapred.TextInputFormat
+                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
diff --git a/ql/src/test/results/clientpositive/runtime_skewjoin_mapjoin_spark.q.out b/ql/src/test/results/clientpositive/runtime_skewjoin_mapjoin_spark.q.out
index 7750d1e..889a9d0 100644
--- a/ql/src/test/results/clientpositive/runtime_skewjoin_mapjoin_spark.q.out
+++ b/ql/src/test/results/clientpositive/runtime_skewjoin_mapjoin_spark.q.out
@@ -164,17 +164,13 @@ STAGE PLANS:
           mode: mergepartial
           outputColumnNames: _col0
           Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: _col0 (type: bigint)
-            outputColumnNames: _col0
+          File Output Operator
+            compressed: false
             Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-            File Output Operator
-              compressed: false
-              Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-28
     Map Reduce Local Work
diff --git a/ql/src/test/results/clientpositive/spark/groupby_complex_types_multi_single_reducer.q.out b/ql/src/test/results/clientpositive/spark/groupby_complex_types_multi_single_reducer.q.out
index 9118845..9fe3b72 100644
--- a/ql/src/test/results/clientpositive/spark/groupby_complex_types_multi_single_reducer.q.out
+++ b/ql/src/test/results/clientpositive/spark/groupby_complex_types_multi_single_reducer.q.out
@@ -204,16 +204,16 @@ POSTHOOK: query: SELECT DEST1.* FROM DEST1
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest1
 #### A masked pattern was here ####
-["166"]	1
-["169"]	4
+["118"]	2
+["180"]	1
+["201"]	1
+["202"]	1
 ["238"]	2
-["258"]	1
-["306"]	1
-["384"]	3
-["392"]	1
-["435"]	1
-["455"]	1
-["468"]	4
+["273"]	3
+["282"]	2
+["419"]	1
+["432"]	1
+["467"]	1
 PREHOOK: query: SELECT DEST2.* FROM DEST2
 PREHOOK: type: QUERY
 PREHOOK: Input: default@dest2
@@ -222,13 +222,13 @@ POSTHOOK: query: SELECT DEST2.* FROM DEST2
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@dest2
 #### A masked pattern was here ####
-{"120":"val_120"}	2
-{"129":"val_129"}	2
-{"160":"val_160"}	1
-{"26":"val_26"}	2
-{"27":"val_27"}	1
-{"288":"val_288"}	2
-{"298":"val_298"}	3
-{"30":"val_30"}	1
-{"311":"val_311"}	3
-{"74":"val_74"}	1
+{"0":"val_0"}	3
+{"138":"val_138"}	4
+{"170":"val_170"}	1
+{"19":"val_19"}	1
+{"222":"val_222"}	1
+{"223":"val_223"}	2
+{"226":"val_226"}	1
+{"489":"val_489"}	4
+{"8":"val_8"}	1
+{"80":"val_80"}	1
diff --git a/ql/src/test/results/clientpositive/spark/lateral_view_explode2.q.out b/ql/src/test/results/clientpositive/spark/lateral_view_explode2.q.out
index 07f7349..41d60f5 100644
--- a/ql/src/test/results/clientpositive/spark/lateral_view_explode2.q.out
+++ b/ql/src/test/results/clientpositive/spark/lateral_view_explode2.q.out
@@ -68,20 +68,16 @@ STAGE PLANS:
                 mode: mergepartial
                 outputColumnNames: _col0, _col1
                 Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-                Select Operator
-                  expressions: _col0 (type: int), _col1 (type: int)
-                  outputColumnNames: _col0, _col1
+                Limit
+                  Number of rows: 3
                   Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-                  Limit
-                    Number of rows: 3
+                  File Output Operator
+                    compressed: false
                     Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-                    File Output Operator
-                      compressed: false
-                      Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: COMPLETE
-                      table:
-                          input format: org.apache.hadoop.mapred.TextInputFormat
-                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -97,9 +93,9 @@ POSTHOOK: query: SELECT col1, col2 FROM src LATERAL VIEW explode2(array(1,2,3))
 POSTHOOK: type: QUERY
 POSTHOOK: Input: default@src
 #### A masked pattern was here ####
-2	2
-1	1
 3	3
+1	1
+2	2
 PREHOOK: query: DROP TEMPORARY FUNCTION explode2
 PREHOOK: type: DROPFUNCTION
 PREHOOK: Output: explode2
diff --git a/ql/src/test/results/clientpositive/spark/runtime_skewjoin_mapjoin_spark.q.out b/ql/src/test/results/clientpositive/spark/runtime_skewjoin_mapjoin_spark.q.out
index 75872d1..2348058 100644
--- a/ql/src/test/results/clientpositive/spark/runtime_skewjoin_mapjoin_spark.q.out
+++ b/ql/src/test/results/clientpositive/spark/runtime_skewjoin_mapjoin_spark.q.out
@@ -279,17 +279,13 @@ STAGE PLANS:
                 mode: mergepartial
                 outputColumnNames: _col0
                 Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                Select Operator
-                  expressions: _col0 (type: bigint)
-                  outputColumnNames: _col0
+                File Output Operator
+                  compressed: false
                   Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                  File Output Operator
-                    compressed: false
-                    Statistics: Num rows: 1 Data size: 8 Basic stats: COMPLETE Column stats: NONE
-                    table:
-                        input format: org.apache.hadoop.mapred.TextInputFormat
-                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                  table:
+                      input format: org.apache.hadoop.mapred.TextInputFormat
+                      output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                      serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
diff --git a/ql/src/test/results/clientpositive/spark/union_remove_25.q.out b/ql/src/test/results/clientpositive/spark/union_remove_25.q.out
index 9e9110b..c89158a 100644
--- a/ql/src/test/results/clientpositive/spark/union_remove_25.q.out
+++ b/ql/src/test/results/clientpositive/spark/union_remove_25.q.out
@@ -424,7 +424,7 @@ Partition Parameters:
 	numFiles            	2                   
 	numRows             	-1                  
 	rawDataSize         	-1                  
-	totalSize           	6814                
+	totalSize           	6826                
 #### A masked pattern was here ####
 	 	 
 # Storage Information	 	 
diff --git a/ql/src/test/results/clientpositive/udf_in_file.q.out b/ql/src/test/results/clientpositive/udf_in_file.q.out
index c85d25f..5564890 100644
--- a/ql/src/test/results/clientpositive/udf_in_file.q.out
+++ b/ql/src/test/results/clientpositive/udf_in_file.q.out
@@ -59,7 +59,7 @@ STAGE PLANS:
             alias: value_src
             Statistics: Num rows: 0 Data size: 24 Basic stats: PARTIAL Column stats: NONE
             Select Operator
-              expressions: in_file(str_val, '../../data/files/test2.dat') (type: boolean), in_file(ch_val, '../../data/files/test2.dat') (type: boolean), in_file(vch_val, '../../data/files/test2.dat') (type: boolean), in_file(str_val_neg, '../../data/files/test2.dat') (type: boolean), in_file(ch_val_neg, '../../data/files/test2.dat') (type: boolean), in_file(vch_val_neg, '../../data/files/test2.dat') (type: boolean), in_file('303', '../../data/files/test2.dat') (type: boolean), in_file('304', '../../data/files/test2.dat') (type: boolean), in_file(null, '../../data/files/test2.dat') (type: boolean)
+              expressions: in_file(str_val, '../../data/files/test2.dat') (type: boolean), in_file(ch_val, '../../data/files/test2.dat') (type: boolean), in_file(vch_val, '../../data/files/test2.dat') (type: boolean), in_file(str_val_neg, '../../data/files/test2.dat') (type: boolean), in_file(ch_val_neg, '../../data/files/test2.dat') (type: boolean), in_file(vch_val_neg, '../../data/files/test2.dat') (type: boolean), in_file('303', '../../data/files/test2.dat') (type: boolean), in_file('304', '../../data/files/test2.dat') (type: boolean), in_file(UDFToString(null), '../../data/files/test2.dat') (type: boolean)
               outputColumnNames: _col0, _col1, _col2, _col3, _col4, _col5, _col6, _col7, _col8
               Statistics: Num rows: 0 Data size: 24 Basic stats: PARTIAL Column stats: NONE
               Limit
diff --git a/ql/src/test/results/clientpositive/udf_nondeterministic.q.out b/ql/src/test/results/clientpositive/udf_nondeterministic.q.out
index eef5555..4b24e78 100644
--- a/ql/src/test/results/clientpositive/udf_nondeterministic.q.out
+++ b/ql/src/test/results/clientpositive/udf_nondeterministic.q.out
@@ -60,16 +60,16 @@ STAGE PLANS:
             Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
             Filter Operator
               predicate: ((year = 2001) and month is not null) (type: boolean)
-              Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
               Select Operator
                 expressions: month (type: int)
                 outputColumnNames: _col1
-                Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                 Reduce Output Operator
                   key expressions: _col1 (type: int)
                   sort order: +
                   Map-reduce partition columns: _col1 (type: int)
-                  Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+                  Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
           TableScan
             alias: b
             Statistics: Num rows: 1 Data size: 2 Basic stats: COMPLETE Column stats: NONE
@@ -88,14 +88,14 @@ STAGE PLANS:
           keys:
             0 _col1 (type: int)
             1 month (type: int)
-          Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+          Statistics: Num rows: 1 Data size: 2 Basic stats: COMPLETE Column stats: NONE
           Select Operator
             expressions: unix_timestamp('2001-01-01 00:00:00') (type: bigint)
             outputColumnNames: _col0
-            Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+            Statistics: Num rows: 1 Data size: 2 Basic stats: COMPLETE Column stats: NONE
             File Output Operator
               compressed: false
-              Statistics: Num rows: 1 Data size: 7 Basic stats: COMPLETE Column stats: NONE
+              Statistics: Num rows: 1 Data size: 2 Basic stats: COMPLETE Column stats: NONE
               table:
                   input format: org.apache.hadoop.mapred.TextInputFormat
                   output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
diff --git a/ql/src/test/results/clientpositive/unionall_unbalancedppd.q.out b/ql/src/test/results/clientpositive/unionall_unbalancedppd.q.out
index 4461ad3..cbe532b 100644
--- a/ql/src/test/results/clientpositive/unionall_unbalancedppd.q.out
+++ b/ql/src/test/results/clientpositive/unionall_unbalancedppd.q.out
@@ -90,17 +90,13 @@ STAGE PLANS:
                 Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                 Union
                   Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
-                  Select Operator
-                    expressions: _col0 (type: int)
-                    outputColumnNames: _col0
+                  File Output Operator
+                    compressed: false
                     Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
-                    File Output Operator
-                      compressed: false
-                      Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
-                      table:
-                          input format: org.apache.hadoop.mapred.TextInputFormat
-                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
           TableScan
             alias: union_all_bug_test_2
             Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
@@ -113,17 +109,13 @@ STAGE PLANS:
                 Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
                 Union
                   Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
-                  Select Operator
-                    expressions: _col0 (type: int)
-                    outputColumnNames: _col0
+                  File Output Operator
+                    compressed: false
                     Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
-                    File Output Operator
-                      compressed: false
-                      Statistics: Num rows: 0 Data size: 0 Basic stats: NONE Column stats: NONE
-                      table:
-                          input format: org.apache.hadoop.mapred.TextInputFormat
-                          output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                          serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+                    table:
+                        input format: org.apache.hadoop.mapred.TextInputFormat
+                        output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                        serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
@@ -290,9 +282,9 @@ POSTHOOK: type: QUERY
 POSTHOOK: Input: default@union_all_bug_test_1
 POSTHOOK: Input: default@union_all_bug_test_2
 #### A masked pattern was here ####
-0
 1
 0
+0
 PREHOOK: query: SELECT f1
 FROM (
 
diff --git a/ql/src/test/results/clientpositive/vector_aggregate_without_gby.q.out b/ql/src/test/results/clientpositive/vector_aggregate_without_gby.q.out
index e7ad852..1175cb8 100644
--- a/ql/src/test/results/clientpositive/vector_aggregate_without_gby.q.out
+++ b/ql/src/test/results/clientpositive/vector_aggregate_without_gby.q.out
@@ -71,17 +71,13 @@ STAGE PLANS:
           mode: mergepartial
           outputColumnNames: _col0, _col1
           Statistics: Num rows: 1 Data size: 88 Basic stats: COMPLETE Column stats: NONE
-          Select Operator
-            expressions: _col0 (type: int), _col1 (type: string)
-            outputColumnNames: _col0, _col1
+          File Output Operator
+            compressed: false
             Statistics: Num rows: 1 Data size: 88 Basic stats: COMPLETE Column stats: NONE
-            File Output Operator
-              compressed: false
-              Statistics: Num rows: 1 Data size: 88 Basic stats: COMPLETE Column stats: NONE
-              table:
-                  input format: org.apache.hadoop.mapred.TextInputFormat
-                  output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
-                  serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
+            table:
+                input format: org.apache.hadoop.mapred.TextInputFormat
+                output format: org.apache.hadoop.hive.ql.io.HiveIgnoreKeyTextOutputFormat
+                serde: org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
 
   Stage: Stage-0
     Fetch Operator
-- 
1.7.9.5

